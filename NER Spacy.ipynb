{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POJmPhz4DOyy",
        "outputId": "5fa87d2f-c230-4236-eb9b-08e1d3455431"
      },
      "outputs": [],
      "source": [
        "# !pip install spacy pandas\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sIdZBRoDy4D"
      },
      "source": [
        "Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re-k1eQ0D_Rt",
        "outputId": "8c235d9a-be6c-46dc-898e-29b76dd66290"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yayNrt6JF9qI"
      },
      "source": [
        "Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K75F7z0mISB6",
        "outputId": "7b67b49d-e0df-4f67-dc66-1f85ba20dd61"
      },
      "outputs": [],
      "source": [
        "def extract_ent(text):\n",
        "  doc = nlp(text)\n",
        "  entList = []\n",
        "  for ent in doc.ents:\n",
        "    entList.append({\n",
        "      \"text\": ent.text,\n",
        "      \"n_word\": len(ent.text.split(\" \")),\n",
        "      \"start_pos\": ent.start_char,\n",
        "      \"end_pos\": ent.end_char,\n",
        "      \"label\": ent.label_\n",
        "    })\n",
        "  return pd.DataFrame(entList)\n",
        "\n",
        "\n",
        "df = pd.read_csv('physics_and_chemistry_nobel_laureate.csv')\n",
        "\n",
        "df_entities_spacy = pd.DataFrame()\n",
        "for index, row in df.iterrows():\n",
        "  text = row['biography']\n",
        "  category = row['category']\n",
        "  subject = row[\"name\"]\n",
        "  df_ents = extract_ent(text)\n",
        "  df_ents['subject'] = subject\n",
        "  df_ents['source_index'] = index\n",
        "  df_ents[\"category\"] = category\n",
        "\n",
        "  df_entities_spacy = pd.concat([df_entities_spacy, df_ents], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>n_word</th>\n",
              "      <th>start_pos</th>\n",
              "      <th>end_pos</th>\n",
              "      <th>label</th>\n",
              "      <th>subject</th>\n",
              "      <th>source_index</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wilhelm Conrad Röntgen</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>Wilhelm Röntgen</td>\n",
              "      <td>0</td>\n",
              "      <td>Physics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>German</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>32</td>\n",
              "      <td>NORP</td>\n",
              "      <td>Wilhelm Röntgen</td>\n",
              "      <td>0</td>\n",
              "      <td>Physics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27 March 1845</td>\n",
              "      <td>3</td>\n",
              "      <td>70</td>\n",
              "      <td>83</td>\n",
              "      <td>DATE</td>\n",
              "      <td>Wilhelm Röntgen</td>\n",
              "      <td>0</td>\n",
              "      <td>Physics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10 February 1923</td>\n",
              "      <td>3</td>\n",
              "      <td>86</td>\n",
              "      <td>102</td>\n",
              "      <td>DATE</td>\n",
              "      <td>Wilhelm Röntgen</td>\n",
              "      <td>0</td>\n",
              "      <td>Physics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>German</td>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>116</td>\n",
              "      <td>NORP</td>\n",
              "      <td>Wilhelm Röntgen</td>\n",
              "      <td>0</td>\n",
              "      <td>Physics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     text  n_word  start_pos  end_pos   label  \\\n",
              "0  Wilhelm Conrad Röntgen       3          0       22  PERSON   \n",
              "1                  German       1         26       32    NORP   \n",
              "2           27 March 1845       3         70       83    DATE   \n",
              "3        10 February 1923       3         86      102    DATE   \n",
              "4                  German       1        110      116    NORP   \n",
              "\n",
              "           subject  source_index category  \n",
              "0  Wilhelm Röntgen             0  Physics  \n",
              "1  Wilhelm Röntgen             0  Physics  \n",
              "2  Wilhelm Röntgen             0  Physics  \n",
              "3  Wilhelm Röntgen             0  Physics  \n",
              "4  Wilhelm Röntgen             0  Physics  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_entities_spacy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistics for Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCYtfTMgMMlW"
      },
      "outputs": [],
      "source": [
        "# def computeStats(df_ents):\n",
        "\n",
        "#     stats_count = df_ents['label'].value_counts().describe()\n",
        "\n",
        "#     df_ents['length'] = df_ents['text'].apply(len)\n",
        "#     stats_length = df_ents.groupby('label')['length'].describe()\n",
        "\n",
        "#     return stats_count, stats_length\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to compare 2 entity dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_entities_stanza = pd.read_csv(\"df_entities_stanza.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HACK to fix the subject things\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_entities_stanza[\"subject\"] = df_entities_stanza[\"source_index\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_no_duplicates = df_entities_spacy[[\"subject\", \"source_index\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_no_duplicates = df_no_duplicates.drop_duplicates()\n",
        "df_no_duplicates.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>source_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wilhelm Röntgen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hendrik Lorentz</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pieter Zeeman</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Henri Becquerel</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pierre Curie</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>Aaron Klug</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Henry Taube</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>Robert Bruce Merrifield</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Herbert A. Hauptman</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>Jerome Karle</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     subject  source_index\n",
              "0            Wilhelm Röntgen             0\n",
              "1            Hendrik Lorentz             1\n",
              "2              Pieter Zeeman             2\n",
              "3            Henri Becquerel             3\n",
              "4               Pierre Curie             4\n",
              "..                       ...           ...\n",
              "195               Aaron Klug           195\n",
              "196              Henry Taube           196\n",
              "197  Robert Bruce Merrifield           197\n",
              "198      Herbert A. Hauptman           198\n",
              "199             Jerome Karle           199\n",
              "\n",
              "[200 rows x 2 columns]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_no_duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_subjects = df_no_duplicates[\"subject\"].to_list()\n",
        "list_indexes = df_no_duplicates[\"source_index\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_subjects = df_entities_spacy[\"subject\"].to_list()\n",
        "list_indexes = df_entities_spacy[\"source_index\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "translation_dict = {}\n",
        "for index in list_indexes:\n",
        "    translation_dict[index] = list_subjects[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_entities_stanza[\"subject\"] = df_entities_stanza[\"source_index\"].replace(translation_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_entities_stanza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "6ZrjQ2EvwT9_",
        "outputId": "d16050a3-bb3d-44d1-fc1e-344ebd33c66f"
      },
      "outputs": [],
      "source": [
        "list_people = np.unique(df_entities_spacy[\"subject\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'if' statement on line 40 (188539401.py, line 82)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[129], line 82\u001b[1;36m\u001b[0m\n\u001b[1;33m    common_labels = [(ent, dict_label_spacy[ent]) for ent in common_entities if dict_label_spacy[ent] == dict_label_stanza[ent]]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 40\n"
          ]
        }
      ],
      "source": [
        "aggregate_results = []\n",
        "\n",
        "for people in list_people:\n",
        "    \n",
        "    results = {}\n",
        "    results[\"subject\"] = people\n",
        "    \n",
        "    filter_df_spacy = df_entities_spacy[df_entities_spacy[\"subject\"] == people][[\"text\", \"label\", \"start_pos\", \"end_pos\"]]\n",
        "    filter_df_stanza = df_entities_stanza[df_entities_stanza[\"subject\"] == people][[\"text\", \"label\", \"start_pos\", \"end_pos\"]]\n",
        "    \n",
        "    entities_spacy = filter_df_spacy[\"text\"].to_list()\n",
        "    entities_stanza = filter_df_stanza[\"text\"].to_list()\n",
        "    \n",
        "    labels_spacy = filter_df_spacy[\"label\"].to_list()\n",
        "    labels_stanza = filter_df_stanza[\"label\"].to_list()\n",
        "    \n",
        "    dict_label_spacy = {k:v for k in entities_spacy for v in labels_spacy}\n",
        "    dict_label_stanza = {k:v for k in entities_stanza for v in labels_stanza}    \n",
        "    \n",
        "    # Entity agreements\n",
        "    common_entities = [ent for ent in entities_spacy if ent in entities_stanza]\n",
        "    \n",
        "    spacy_diff = [ent for ent in entities_spacy if ent not in entities_stanza]\n",
        "    stanza_diff =  [ent for ent in entities_stanza if ent not in entities_spacy]\n",
        "    \n",
        "    total_num_entities = len(common_entities) + len(spacy_diff) + len(stanza_diff)\n",
        "    diff_spacy = len(spacy_diff)/total_num_entities\n",
        "    diff_stanza = len(stanza_diff)/total_num_entities\n",
        "    \n",
        "    total_num_disagreements = len(spacy_diff) + len(stanza_diff)\n",
        "    \n",
        "    agreement_entities = len(common_entities)/total_num_entities\n",
        "    \n",
        "    results[\"agreement_entities\"] = agreement_entities\n",
        "    results[\"diff_spacy_entities\"] = diff_spacy\n",
        "    results[\"diff_stanza_entities\"] = diff_stanza\n",
        "    \n",
        "    #Partial Span agreement\n",
        "    \n",
        "    if agreement_entities != 1.0: # if the agreement is not total - avoid zero division\n",
        "        \n",
        "        print(\"skip for now\")\n",
        "        \n",
        "        # Issue with getting the spans for the entities:\n",
        "        # sometimes the entity appears more than once so we can't get the index by filtering like filter[filter[\"text\"] = ent] \n",
        "        # since it will return more than one value\n",
        "        # ideally, a way to get each entity with its index to do filter[index][start] and filter[index][stop] instead\n",
        "    \n",
        "        # spacy_spans = []\n",
        "        # for entity in spacy_diff:\n",
        "        #     start = filter_df_spacy[\"start_pos\"]\n",
        "        #     stop = filter_df_spacy[\"end_pos\"]\n",
        "        #     print(start, stop)\n",
        "        #     entity_spans = np.arange(start, stop + 1, 1) # CHECK IF THE STOP SPAN IN SPACY IS INCLUDING OR EXCLUDING\n",
        "        #     spacy_spans.append(entity_spans)\n",
        "\n",
        "        # stanza_spans = []\n",
        "        # for entity in stanza_diff:\n",
        "        #     start = filter_df_stanza[\"start_pos\"]\n",
        "        #     stop = filter_df_stanza[\"end_pos\"]\n",
        "        #     print(start, stop)\n",
        "        #     entity_spans = np.arange(start, stop + 1, 1) # CHECK IF THE STOP SPAN IN STANZA IS INCLUDING OR EXCLUDING\n",
        "        #     stanza_spans.append(entity_spans)\n",
        "\n",
        "        # common_entity_spans = []\n",
        "        # for entity_span_spacy in spacy_spans:\n",
        "        #     for entity_span_stanza in stanza_spans:\n",
        "        #         common_span = [index for index in entity_span_spacy if index in entity_span_stanza]\n",
        "        #         if len(common_span) > 1:\n",
        "        #             n_entity_spacy = spacy_spans.index(entity_span_spacy)\n",
        "        #             n_entity_stanza = stanza_spans.index(entity_span_stanza)\n",
        "        #             tuple_indexes = (n_entity_spacy, n_entity_stanza)\n",
        "        #             common_entity_spans.append(tuple_indexes)\n",
        "        \n",
        "        # common_entity_spans = set(common_entity_spans)\n",
        "        # partial_agreement_ratio = len(common_entity_spans)/total_num_disagreements\n",
        "        # results[\"partial_agreements_over_total_disagreements\"] = partial_agreement_ratio\n",
        "        \n",
        "        # total_partial_agreements = (len(common_entity_spans) + len(common_entities))/total_num_entities\n",
        "        # results[\"partial_agreements\"] = total_partial_agreements\n",
        "    \n",
        "    # Label agreements\n",
        "    common_labels = [(ent, dict_label_spacy[ent]) for ent in common_entities if dict_label_spacy[ent] == dict_label_stanza[ent]]\n",
        "    spacy_label_diff = [(ent, dict_label_spacy[ent]) for ent in common_entities if dict_label_spacy[ent] != dict_label_stanza[ent]]\n",
        "    stanza_label_diff =  [(ent, dict_label_stanza[ent]) for ent in common_entities if dict_label_spacy[ent] != dict_label_stanza[ent]]\n",
        "    \n",
        "    if len(common_labels) > 0:\n",
        "        agreement_labels = len(common_labels)/len(common_entities)\n",
        "    else:\n",
        "        agreement_labels = 0\n",
        "    \n",
        "    results[\"agreement_labels\"] = agreement_labels\n",
        "    \n",
        "    \n",
        "    if len(common_entities) == len(entities_stanza):\n",
        "        agreement = \"Total Agreement\"\n",
        "    else: \n",
        "        agreement = \"Partial Agreement\"\n",
        "    \n",
        "    aggregate_results.append(results)\n",
        "    \n",
        "    ############# LETF TO DO: COMPUTE STATS OF ACCURACY ETC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aggregate_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INTER ANNOTATOR AGREEMENT BETWEEN THE TWO PACKAGES"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
